from typing import Literal
AvailModels = Literal[
	"openai|gpt-4o",
	"openai|gpt-4",
	"openai|gpt-4o-mini",
	"openai|gpt-4-turbo",
	"openai|gpt-4-0613",
	"openai|gpt-3.5-turbo",
	"openai|ft:gpt-3.5-turbo-0125:personal:doktor:8xHAc2HS",
	"openai|gpt-3.5-turbo-0125",
	"openai|gpt-4-turbo-preview",
	"openai|gpt-4-0125-preview",
	"openai|gpt-3.5-turbo-1106",
	"openai|gpt-4-1106-preview",
	"openai|gpt-3.5-turbo-instruct",
	"openai|gpt-3.5-turbo-16k",
	"openai|gpt-4o-2024-08-06",
	"openai|gpt-4o-2024-05-13",
	"openai|gpt-3.5-turbo-instruct-0914",
	"openai|gpt-4o-mini-2024-07-18",
	"openai|gpt-4-turbo-2024-04-09",
	"anthropic|claude-3-5-sonnet-20240620",
	"anthropic|claude-3-opus-20240229",
	"anthropic|claude-3-sonnet-20240229",
	"anthropic|claude-3-haiku-20240307",
	"deepseek|deepseek-chat",
	"deepseek|deepseek-coder",
	"deepinfra|microsoft/WizardLM-2-8x22B",
	"deepinfra|meta-llama/Meta-Llama-3.1-70B-Instruct",
	"deepinfra|meta-llama/Meta-Llama-3.1-8B-Instruct",
	"deepinfra|mistralai/Mixtral-8x22B-Instruct-v0.1",
	"deepinfra|meta-llama/Meta-Llama-3.1-405B-Instruct",
	"deepinfra|Qwen/Qwen2-72B-Instruct",
	"deepinfra|llava-hf/llava-1.5-7b-hf",
	"deepinfra|mistralai/Mistral-7B-Instruct-v0.3",
	"ollama|bge-m3:latest",
	"ollama|deepseek-coder-v2:16b",
	"ollama|starcoder2:latest",
	"ollama|codeqwen:latest",
	"ollama|deepseek-coder-v2:16b-lite-instruct-q6_K",
	"ollama|mixbai:latest",
	"ollama|wizardlm2:7b-q6_K",
	"ollama|phi3:latest"
    "google|gemini-1.5-flash",
    "google|gemini-1.5-pro",
]
